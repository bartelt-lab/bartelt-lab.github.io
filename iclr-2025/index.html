<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Hello World</title>
    <link rel="stylesheet" href="style.css">

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400..800;1,400..800&family=Fira+Code:wght@300..700&family=Inter:ital,opsz,wght@0,14..32,100..900;1,14..32,100..900&family=Montserrat:ital,wght@0,100..900;1,100..900&family=Nunito+Sans:ital,opsz,wght@0,6..12,200..1000;1,6..12,200..1000&family=Open+Sans:ital,wght@0,300..800;1,300..800&family=PT+Serif:ital,wght@0,400;0,700;1,400;1,700&family=Poppins:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&family=Roboto+Mono:ital,wght@0,100..700;1,100..700&family=Source+Code+Pro:ital,wght@0,200..900;1,200..900&display=swap" rel="stylesheet">
</head>
<body>
    <div class="banner">
        <div class="container">
            <div class="banner-text">CORE research group at ICLR 2025</div>
        </div>
    </div>
    <div class="container">
        <div class="content">
            <div class="content-text">
                6 papers authored or co-authored by CORE members have been accepted at the main conference and workshops at The 2025 International Conference on Learning Representations (ICLR) in Singapore.
            </div>
        </div>

        <h2>Main Conference</h2>

        <a href="https://arxiv.org/abs/2408.08761" class="card-link">
            <div class="card">
                <div class="left">
                    <img src="assets/marton_mitigating.png" alt="Paper Preview">
                </div>
                <div class="right">
                    <div class="title">Mitigating Information Loss in Tree-Based Reinforcement Learning via Direct Optimization</div>
                    <div class="tags">
                        <div class="tag">University of Mannheim</div>
                        <div class="tag">TU Clausthal</div>
                        <div class="tag">University of Rostock</div>
                    </div>
                    <div class="description">
                        The paper introduces SYMPOL, a novel method that integrates symbolic, tree-based models with policy gradient methods to enhance interpretability in reinforcement learning (RL). 
                        By enabling direct, end-to-end optimization of axis-aligned decision trees within standard on-policy RL algorithms, SYMPOL addresses the challenge of information loss associated with traditional neural network policies. 
                    </div>
                </div>
            </div>
        </a>

        <a href="https://arxiv.org/abs/2407.14561" class="card-link">
            <div class="card">
                <div class="left">
                    <img src="assets/ndif.png" alt="Paper Preview">
                </div>
                <div class="right">
                    <div class="title">NNsight and NDIF: Democratizing Access to Open-Weight Foundation Model Internals</div>
                    <div class="tags">
                        <div class="tag">Northeastern University</div>
                        <div class="tag">TU Clausthal</div>
                        <div class="tag">University of Hamburg</div>
                    </div>
                    <div class="description">
                        The paper introduces NNsight, an open-source extension to PyTorch enabling deferred remote execution, and NDIF, a scalable inference service for sharing GPU resources and pretrained models. 
                        Together, they facilitate transparent access to the internals of large neural networks, such as large language models, without requiring individual hosting of customized models.
                    </div>
                </div>
            </div>
        </a>

        <h2>Workshops</h2>

        <a href="https://arxiv.org/abs/2501.08925" class="card-link">
            <div class="card">
                <div class="left">
                    <img src="assets/grams_disentangling.png" alt="Paper Preview">
                </div>
                <div class="right">
                    <div class="title">Disentangling Exploration of Large Language Models by Optimal Exploitation</div>
                    <div class="tags">
                        <div class="tag">TU Clausthal</div>
                        <div class="tag">University of Mannheim</div>
                    </div>
                    <div class="description">
                        The paper investigates the exploration capabilities of large language models (LLMs) by isolating exploration as the sole objective and introducing a framework that decomposes missing rewards into exploration and exploitation components based on the optimal achievable return.
                    </div>
                </div>
            </div>
        </a>

        <a href="https://arxiv.org/abs/2503.08738" class="card-link">
            <div class="card">
                <div class="left">
                    <img src="assets/zenkner_shedding.png" alt="Paper Preview">
                </div>
                <div class="right">
                    <div class="title">Shedding Light on Task Decomposition in Program Synthesis: The Driving Force of the Synthesizer Model</div>
                    <div class="tags">
                        <div class="tag">TU Clausthal</div>
                    </div>
                    <div class="description">
                        This paper compares ExeDec, a program synthesis framework that uses explicit task decomposition, with REGISM, its variant that relies solely on iterative execution-guided synthesis. 
                        While ExeDec shows strong performance in length generalization and concept composition due to its decomposition strategy, REGISM often matches or exceeds its performance, suggesting that repeated execution can be equally or more effective in many scenarios.
                    </div>
                </div>
            </div>
        </a>

        <a href="https://arxiv.org/abs/2403.07733" class="card-link">
            <div class="card">
                <div class="left">
                    <img src="assets/dseg_lime.png" alt="Paper Preview">
                </div>
                <div class="right">
                    <div class="title">Beyond Pixels: Enhancing LIME with Hierarchical Features and Segmentation Foundation Models</div>
                    <div class="tags">
                        <div class="tag">TU Clausthal</div>
                        <div class="tag">University of Mannheim</div>
                    </div>
                    <div class="description">
                        The paper introduces DSEG-LIME, an improved framework for Local Interpretable Model-agnostic Explanations (LIME) in image analysis. 
                        By integrating data-driven segmentation through foundation models and enabling user-controlled hierarchical segmentation, DSEG-LIME enhances interpretability by aligning explanations more closely with human-recognized concepts, outperforming traditional methods on several explainable AI metrics.
                    </div>
                </div>
            </div>
        </a>

        <a href="https://arxiv.org/abs/2503.09159" class="card-link">
            <div class="card">
                <div class="left">
                    <img src="assets/tschalzev_unreflected.png" alt="Paper Preview">
                </div>
                <div class="right">
                    <div class="title">Unreflected Use of Tabular Data Repositories Can Undermine Research Quality</div>
                    <div class="tags">
                        <div class="tag">University of Mannheim</div>
                        <div class="tag">TU Clausthal</div>
                        <div class="tag">University of Rostock</div>
                        <div class="tag">University of Freiburg</div>
                    </div>
                    <div class="description">
                        The paper highlights that indiscriminate utilization of datasets from repositories like OpenML may compromise research integrity. 
                        The authors present cases illustrating issues such as suboptimal model selection, neglect of robust baselines, and improper preprocessing, and propose enhancements to data repository practices to bolster empirical research standards. 
                    </div>
                </div>
            </div>
        </a>

    </div>
</body>
</html>