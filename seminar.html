<!doctype html>
<html lang=en>
<head>   
    <!-- Header component will be loaded here -->
    <div id="header-placeholder"></div>
</head>
<body>
    <!-- Introduction to AI Section -->
    <section id="intro-ai" class="home-section">
        <div class="container">
            <p>
                We offer seminars that dive into current research questions and recent developments in our field.
                These are a great opportunity to engage with cutting-edge topics, practice critical thinking, and get a feel for ongoing work in the lab and beyond. 
                Below is a list of seminar topics we have recently offered or are planning for upcoming terms.
            </p>
        </div>
    </section>

    <!-- Theses Section -->
    <section id="topics" class="home-section">
        <div class="container">
        <div class="row">
            <div class="col-xs-12 col-md-3 section-heading">
            <h1>Process</h1>
            </div>
            <div class="col-xs-12 col-md-9">
            <div class="course-list-item" itemscope itemtype="http://schema.org/CreativeWork">
                <div class="row">
                <div class="col-sm-12">

                    <div class="seminar-process" style="margin-top: 1.5em;">
                    <ol>
                        <li>
                            <strong>Application:</strong> Send your Transcript of Records (CV optional) and topic preferences to 
                            <a href="mailto:patrick.knab@tu-clausthal.de">patrick.knab@tu-clausthal.de</a>.
                        </li>
                        <li>
                            <strong>Selection:</strong> You will be informed whether you have been accepted due to limited slots.
                        </li>
                        <li>
                            <strong>Kick-Off Meeting:</strong> Introductory session & milestone schedule announcement.
                        </li>
                        <li>
                            <strong>Milestone 1:</strong> Submit your seminar paper (~2.5 months in).
                        </li>
                        <li>
                            <strong>Milestone 2:</strong> Write two peer reviews.
                        </li>
                        <li>
                            <strong>Milestone 3:</strong> Present your paper to the group.
                        </li>
                        <li>
                            <strong>Milestone 4:</strong> Submit the camera-ready paper & change log.
                        </li>
                        </ol>
                    </div>
    
                </div>
                </div>
            </div>
            </div>
        </div>
        </div>
    </section>


    <section id="seminar" class="home-section">
    <div class="container">
        <div class="row">
        <div class="col-xs-12 col-md-3 section-heading">
            <h1>Seminar Topics</h1>
            <p style="font-size: 0.9em; color: #666;">Winter Semester 2025</p>
        </div>
        <div class="col-xs-12 col-md-9">
            <div class="course-list-item" itemscope itemtype="http://schema.org/CreativeWork">
            <div class="row">
                <div class="col-sm-12">
                <div class="course-description">
                    The following seminar topics are available. Click on each to expand the full description and objectives.
                </div>

                <style>
                    details {
                    margin-bottom: 1.5em;
                    }
                    details summary {
                    cursor: pointer;
                    position: relative;
                    padding-left: 1.2em;
                    font-weight: bold;
                    line-height: 1.4;
                    }
                    details summary::before {
                    content: '\25B6';
                    position: absolute;
                    left: 0;
                    transition: transform 0.2s ease;
                    }
                    details[open] summary::before {
                    content: '\25BC';
                    }
                    details summary:hover {
                    background: rgba(0, 123, 255, 0.05);
                    color: #007bff;
                    }
                    details summary:hover::before {
                    color: #007bff;
                    }
                </style>

                <div class="thesis-topics" style="margin-top: 1.5em;">

                    <details>
                    <summary>Approaches to Program Synthesis from Natural Language</summary>
                    <p>This seminar paper explores how machine learning, particularly neural network-based models, can be used to automatically generate computer programs from natural language descriptions. The central goal of these approaches is to enable users to describe their intent in everyday language and receive executable code in response — without manually writing any code.</p>
                    <p>The paper focuses on data-driven techniques, including transformer-based language models and fine-tuned models trained on code-text pairs. These models aim to learn the mapping between natural language specifications and source code by generalizing from large-scale training data.</p>
                    <p>Key aspects discussed include model architectures, input-output representations (e.g., code as text vs. abstract syntax trees), and the role of domain-specific languages (DSLs) in constraining the output space. The paper also examines how these systems are evaluated, the limitations they face (e.g., ambiguity in natural language, lack of precise specifications), and strategies to improve reliability, such as retrieval-based augmentation or user-in-the-loop guidance.</p>
                    <p>Finally, the seminar will highlight current trends and open research challenges, including improving generalization, handling complex multi-step tasks, and ensuring correctness and security in synthesized programs.</p>
                    <strong>Objectives:</strong>
                    <ul>
                        <li>Summarize modern ML-based and neural approaches to program synthesis from natural language</li>
                        <li>Analyze the capabilities and limitations of current models</li>
                        <li>Explore evaluation strategies and benchmark tasks</li>
                        <li>Identify emerging trends and future research directions</li>
                    </ul>
                    </details>

                    <details>
                    <summary>Inductive vs. Transductive Approaches in Programming-by-Example: A Comparative Study and Evaluation Benchmarks</summary>
                    <p>Programming-by-Example (PBE) is a paradigm in which a system learns to generate a program purely from a small set of input-output examples, without requiring an explicit description of the task. It aims to mimic how humans can infer a general rule from just a few demonstrations.</p>
                    <p>Within this domain, two complementary paradigms have emerged: inductive and transductive synthesis. Inductive PBE methods attempt to generate a general program that is consistent with all provided examples. The resulting program can typically be applied to new, unseen inputs. Transductive PBE methods directly predict the output for a specific input using the training examples, without necessarily inferring a reusable program.</p>
                    <p>This seminar paper provides a comparative analysis of these two paradigms. It investigates the underlying assumptions, strengths, and limitations of inductive and transductive approaches, and discusses when each is more suitable — for instance, generalization vs. specificity, interpretability vs. performance.</p>
                    <p>The work also presents a curated collection of benchmark datasets that are commonly used to evaluate PBE models. These include both classical and modern datasets designed to test compositional generalization, robustness, domain transfer, and step-wise reasoning. Each benchmark is categorized by domain (e.g., string manipulation, list processing), task type (e.g., single-step, multi-step), and which paradigm(s) it best evaluates.</p>
                    <strong>Objectives:</strong>
                    <ul>
                        <li>Provide a structured comparison of inductive and transductive PBE approaches</li>
                        <li>Identify typical use cases and limitations for both paradigms</li>
                        <li>Collect and categorize publicly available benchmarks for fair and comprehensive evaluation</li>
                        <li>Highlight open research questions and opportunities for hybrid or adaptive approaches</li>
                    </ul>
                    </details>

                    <details>
                    <summary>Real-World Applications of Concept Bottleneck Models Beyond Image Classification</summary>
                    <p>Concept Bottleneck Models (CBMs) offer a promising framework for interpretable machine learning by predicting high-level, human-understandable concepts as an intermediate step before making final predictions. Unlike standard end-to-end neural networks, CBMs enable direct inspection, validation, and even manual intervention at the concept level—offering a transparent interface between data and decision.</p>
                    <p>This seminar paper explores how CBMs are being adopted and adapted in real-world domains, with a particular focus on applications beyond conventional image classification tasks (e.g., ImageNet). The student will investigate in which settings CBMs have demonstrated practical value or have been purposefully designed for domain-specific challenges. These include, but are not limited to, applications in medicine (e.g., diagnosis from visual or structured data), science and engineering (e.g., interpretable control or simulations), and safety-critical fields such as autonomous driving or environmental monitoring.</p>
                    <p>The paper will analyze how domain constraints influence concept design, supervision strategies (manual vs. discovered concepts), and the trade-offs between interpretability and predictive performance. Special attention should be paid to how concepts are defined, how well they align with domain knowledge, and how user-in-the-loop methods leverage CBM explanations for interactive decision-making.</p>
                    <p>Further aspects may include:</p>
                    <ul>
                        <li>The architecture and training pipelines of domain-adapted CBMs</li>
                        <li>Evaluation metrics that capture both task performance and explanation quality</li>
                        <li>Examples where CBMs improve trust, robustness, or fairness in decision-making</li>
                        <li>Known limitations or failure cases of CBMs in practice</li>
                    </ul>
                    <strong>Objectives:</strong>
                    <ul>
                        <li>Map the current landscape of CBM use in applied settings beyond general-purpose image tasks</li>
                        <li>Understand how domain-specific needs shape concept design and evaluation</li>
                        <li>Critically assess the benefits and limitations of CBMs in practical use</li>
                        <li>Identify opportunities for future work in expanding CBMs into new domains or modalities</li>
                    </ul>
                    </details>

                    <details>
                    <summary>Guiding World Models with Visual Concepts: Enhancing Interpretability in Embodied AI</summary>
                    <p>In the realm of embodied AI, world models are pivotal for enabling agents to predict and interact with their environments. Traditionally, these models process raw sensory data, which can be opaque and challenging to interpret. Recent advancements suggest that integrating human-understandable visual concepts—such as object categories or spatial relationships—can serve as effective prompts, enhancing both the performance and interpretability of these models.</p>
                    <p>This seminar explores how visual concepts are employed to guide world models in embodied AI systems. By examining a selection of recent studies, the paper will analyze methods where visual concepts are used to prompt models, facilitating tasks like navigation, manipulation, and decision-making. The focus will be on understanding the mechanisms of this integration and its impact on model transparency and user interaction.</p>
                    <strong>Objectives:</strong>
                    <ul>
                        <li>Review key methodologies that incorporate visual concepts into world models within embodied AI</li>
                        <li>Analyze the benefits of using visual prompts for enhancing model interpretability and performance</li>
                        <li>Discuss challenges and limitations associated with this approach</li>
                        <li>Identify potential directions for future research in concept-guided world modeling</li>
                    </ul>
                    </details>

                    <details>
                    <summary>Large Language Models for Software Engineering: Current Applications and Future Directions</summary>
                    <p>Large Language Models (LLMs) have demonstrated remarkable capabilities in understanding and generating code, leading to their widespread adoption in software engineering tasks. This seminar paper explores the current landscape of LLM applications in software engineering, examining both their successes and limitations.</p>
                    <p>The paper will cover key areas where LLMs are being applied, including code generation, bug detection, code review, documentation generation, and program understanding. It will analyze the effectiveness of different approaches, such as fine-tuning on code datasets, prompt engineering techniques, and integration with development tools.</p>
                    <p>Special attention will be given to evaluation methodologies, including both automated metrics and human-centric assessments. The paper will also discuss challenges such as hallucination, security concerns, and the need for domain-specific adaptations.</p>
                    <strong>Objectives:</strong>
                    <ul>
                        <li>Survey current LLM applications in software engineering</li>
                        <li>Analyze evaluation strategies and benchmarks</li>
                        <li>Identify challenges and limitations</li>
                        <li>Explore future research directions and opportunities</li>
                    </ul>
                    </details>

                </div>
                </div>
            </div>
            </div>
        </div>
        </div>
    </section>

    <!-- Footer component will be loaded here -->
    <div id="footer-placeholder"></div>

    <!-- Load component loader -->
    <script src="js/components.js"></script>
</body>
</html>
